{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korbirayen/Deep-RL-notebooks/blob/main/notebooks/optuna_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "# Hyperparameter tuning with Optuna\n",
        "\n",
        "Github repo: https://github.com/araffin/tools-for-robotic-rl-icra2022\n",
        "\n",
        "Optuna: https://github.com/optuna/optuna\n",
        "\n",
        "Stable-Baselines3: https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "Documentation: https://stable-baselines3.readthedocs.io/en/master/\n",
        "\n",
        "SB3 Contrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "\n",
        "RL Baselines3 zoo: https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "\n",
        "[RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo) is a collection of pre-trained Reinforcement Learning agents using Stable-Baselines3.\n",
        "\n",
        "It also provides basic scripts for training, evaluating agents, tuning hyperparameters and recording videos.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you will learn the importance of tuning hyperparameters. You will first try to optimize the parameters manually and then we will see how to automate the search using Optuna.\n",
        "\n",
        "\n",
        "## Install Dependencies and Stable Baselines3 Using Pip\n",
        "\n",
        "List of full dependencies can be found in the [README](https://github.com/DLR-RM/stable-baselines3).\n",
        "\n",
        "\n",
        "```\n",
        "pip install stable-baselines3[extra]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hYdv2ygjLaFL",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "95ae37b9-6213-47e3-aa33-2c2e82f7e24d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable-baselines3)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.5.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.1.1\n",
            "    Uninstalling gymnasium-1.1.1:\n",
            "      Successfully uninstalled gymnasium-1.1.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed gymnasium-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oexj67yWN5_k",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "5397c86a-bd58-445e-ac4c-7f78ffa16f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sb3-contrib\n",
            "  Downloading sb3_contrib-2.5.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: stable_baselines3<3.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from sb3-contrib) (2.5.0)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.5.0->sb3-contrib) (1.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3<3.0,>=2.5.0->sb3-contrib) (3.0.2)\n",
            "Downloading sb3_contrib-2.5.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.8/92.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sb3-contrib\n",
            "Successfully installed sb3-contrib-2.5.0\n"
          ]
        }
      ],
      "source": [
        "# Optional: install SB3 contrib to have access to additional algorithms\n",
        "!pip install sb3-contrib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNah91r9x9EL",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "c5861726-282d-4ce7-f9d6-dcc9889ac217",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ],
      "source": [
        "# Optuna will be used in the last part when doing hyperparameter tuning\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BIedd7Pz9sOs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae32CtgzTG3R"
      },
      "source": [
        "The first thing you need to import is the RL model, check the documentation to know what you can use on which problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R7tKaBFrTR0a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO, A2C, SAC, TD3, DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EcsXmYRMON9W",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Algorithms from the contrib repo\n",
        "# https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\n",
        "from sb3_contrib import QRDQN, TQC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kLwjcfvuqtGE",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-khNkrgcI6Z1"
      },
      "source": [
        "# Part I: The Importance Of Tuned Hyperparameters\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PytOtL9GdmrE"
      },
      "source": [
        "When compared with Supervised Learning, Deep Reinforcement Learning is far more sensitive to the choice of hyper-parameters such as learning rate, number of neurons, number of layers, optimizer ... etc.\n",
        "\n",
        "Poor choice of hyper-parameters can lead to poor/unstable convergence. This challenge is compounded by the variability in performance across random seeds (used to initialize the network weights and the environment)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk8HSIC3qUjc"
      },
      "source": [
        "In addition to hyperparameters, selecting the appropriate algorithm is also an important choice. We will demonstrate it on the simple Pendulum task.\n",
        "\n",
        "See [gym doc](https://gym.openai.com/envs/Pendulum-v0/): \"The inverted pendulum swingup problem is a classic problem in the control literature. In this version  of the problem, the pendulum starts in a random position, and the goal is to swing it up so it stays upright.\"\n",
        "\n",
        "\n",
        "Let's try first with PPO and a small budget of 4000 steps (20 episodes):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4ToIvihGq2N0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "env_id = \"Pendulum-v1\"\n",
        "# Env used only for evaluation\n",
        "eval_envs = make_vec_env(env_id, n_envs=10)\n",
        "# 4000 training timesteps\n",
        "budget_pendulum = 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWT2r6QE4yew"
      },
      "source": [
        "### PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KCHk_-_4ndux",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "8bb95b6f-a4bd-4393-ef7f-2aa2294dfb8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP9C9AqLndxz",
        "outputId": "af92a41a-d5f6-4660-ed13-c8bf6e8e1f97",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1175.23 +/- 265.92\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHmJaJLl5ds4"
      },
      "source": [
        "### A2C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BLL_pws25jh0",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "90a1cc64-502d-4f3d-9d8a-daa19de4f279",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define and train a A2C model\n",
        "a2c_model = A2C(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(budget_pendulum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ic83jZwB5nVk",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "5ffd0149-aad3-42fc-bd74-9428abb7b1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A2C Mean episode reward: -1499.16 +/- 41.50\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the train A2C model\n",
        "mean_reward, std_reward = evaluate_policy(a2c_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"A2C Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_z1zFx2rVpG"
      },
      "source": [
        "Both are far from solving the env (mean reward around -200).\n",
        "Now, let's try with an off-policy algorithm:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wYaVZJU5VL5"
      },
      "source": [
        "### Training longer PPO ?\n",
        "\n",
        "Maybe training longer would help?\n",
        "\n",
        "You can try with 10x the budget, but in the case of A2C/PPO, training longer won't help much, finding better hyperparameters is needed instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hHsHpnQY6TWA",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "a3212f1c-a7eb-41b1-8f0f-db86faa572f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# train longer\n",
        "new_budget = 10 * budget_pendulum\n",
        "\n",
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(new_budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7OD9y1o36Xta",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "49ed1597-56b8-45eb-8faf-f9d9e160f4ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PPO Mean episode reward: -1165.18 +/- 233.41\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEvQ9SJ15Xmh"
      },
      "source": [
        "### PPO - Tuned Hyperparameters\n",
        "\n",
        "Using Optuna, we can in fact tune the hyperparameters and find a working solution (from the [RL Zoo](https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "S-D_vvsb6jOZ",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "34ed69de-8e4d-4b20-c103-a4e3f55c3d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'Pendulum-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.24e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 498         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028940294 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.69       |\n",
            "|    explained_variance   | 0.776       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 11.9        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0196     |\n",
            "|    std                  | 0.971       |\n",
            "|    value_loss           | 34.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -1.03e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 481         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021957677 |\n",
            "|    clip_fraction        | 0.194       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.36       |\n",
            "|    explained_variance   | 0.943       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 8.39        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    std                  | 0.553       |\n",
            "|    value_loss           | 20.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -613        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 478         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 64          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022074752 |\n",
            "|    clip_fraction        | 0.27        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 0.373       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    std                  | 0.352       |\n",
            "|    value_loss           | 2.5         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 200         |\n",
            "|    ep_rew_mean          | -325        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 473         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030069264 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 0.722       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00794    |\n",
            "|    std                  | 0.304       |\n",
            "|    value_loss           | 1.43        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 200        |\n",
            "|    ep_rew_mean          | -233       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 471        |\n",
            "|    iterations           | 25         |\n",
            "|    time_elapsed         | 108        |\n",
            "|    total_timesteps      | 51200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04961852 |\n",
            "|    clip_fraction        | 0.201      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.48      |\n",
            "|    explained_variance   | 0.998      |\n",
            "|    learning_rate        | 0.001      |\n",
            "|    loss                 | 0.109      |\n",
            "|    n_updates            | 240        |\n",
            "|    policy_gradient_loss | 0.00146    |\n",
            "|    std                  | 0.249      |\n",
            "|    value_loss           | 0.417      |\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "tuned_params = {\n",
        "    \"gamma\": 0.9,\n",
        "    \"use_sde\": True,\n",
        "    \"sde_sample_freq\": 4,\n",
        "    \"learning_rate\": 1e-3,\n",
        "}\n",
        "\n",
        "# budget = 10 * budget_pendulum\n",
        "ppo_tuned_model = PPO(\"MlpPolicy\", env_id, seed=1, verbose=1, **tuned_params).learn(50_000, log_interval=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLuxoLxt67xO",
        "outputId": "2400172a-2d43-4396-ee78-6dc55401136a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned PPO Mean episode reward: -185.86 +/- 119.02\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(ppo_tuned_model, eval_envs, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"Tuned PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H33u_apWPp5"
      },
      "source": [
        "Note: if you try SAC on the simple MountainCarContinuous environment, you will encounter some issues without tuned hyperparameters: https://github.com/rail-berkeley/softlearning/issues/76\n",
        "\n",
        "Simple environments can be challenging even for SOTA algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vdpPJ04nebx"
      },
      "source": [
        "# Part II: Grad Student Descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8PNN9kcgolk"
      },
      "source": [
        "### Challenge (10 minutes): \"Grad Student Descent\"\n",
        "The challenge is to find the best hyperparameters (max performance) for A2C on `CartPole-v1` with a limited budget of 20 000 training steps.\n",
        "\n",
        "\n",
        "Maximum reward: 500 on `CartPole-v1`\n",
        "\n",
        "The hyperparameters should work for different random seeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "s6aqxsini7H3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "budget = 20_000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDQ805DBi3KM"
      },
      "source": [
        "#### The baseline: default hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pyOCKf4Vt-HK",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "eval_envs_cartpole = make_vec_env(\"CartPole-v1\", n_envs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "D1PSNGcsi2dP",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "2b066e2a-a7c9-4b45-c2a7-a5c7274673a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.2     |\n",
            "|    ep_rew_mean        | 20.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 365      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 500      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | -0.0129  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 1.95     |\n",
            "|    value_loss         | 8.69     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.9     |\n",
            "|    ep_rew_mean        | 19.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 401      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 2        |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | 0.178    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -5.49    |\n",
            "|    value_loss         | 88.4     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 19.6     |\n",
            "|    ep_rew_mean        | 19.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 416      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.691   |\n",
            "|    explained_variance | -0.0665  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 1.81     |\n",
            "|    value_loss         | 7.53     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 19.7      |\n",
            "|    ep_rew_mean        | 19.7      |\n",
            "| time/                 |           |\n",
            "|    fps                | 401       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 4         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.69     |\n",
            "|    explained_variance | -0.000389 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 1.65      |\n",
            "|    value_loss         | 6.52      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 20.7     |\n",
            "|    ep_rew_mean        | 20.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 394      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.68    |\n",
            "|    explained_variance | -0.178   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -12.9    |\n",
            "|    value_loss         | 476      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 21.3     |\n",
            "|    ep_rew_mean        | 21.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 402      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.692   |\n",
            "|    explained_variance | 0.00671  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 1.46     |\n",
            "|    value_loss         | 5.61     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.2     |\n",
            "|    ep_rew_mean        | 22.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 408      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.693   |\n",
            "|    explained_variance | 0.031    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.33     |\n",
            "|    value_loss         | 4.7      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23       |\n",
            "|    ep_rew_mean        | 23       |\n",
            "| time/                 |          |\n",
            "|    fps                | 413      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.689   |\n",
            "|    explained_variance | 0.17     |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 1.32     |\n",
            "|    value_loss         | 4.34     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 24.2     |\n",
            "|    ep_rew_mean        | 24.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 416      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.688   |\n",
            "|    explained_variance | 0.006    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 1.33     |\n",
            "|    value_loss         | 4.33     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.3     |\n",
            "|    ep_rew_mean        | 25.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.625   |\n",
            "|    explained_variance | 0.0399   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 1.54     |\n",
            "|    value_loss         | 3.87     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 29.1     |\n",
            "|    ep_rew_mean        | 29.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 423      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 12       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.671   |\n",
            "|    explained_variance | 0.00653  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.939    |\n",
            "|    value_loss         | 3.27     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.3     |\n",
            "|    ep_rew_mean        | 32.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 425      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 14       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.62    |\n",
            "|    explained_variance | 0.0192   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.995    |\n",
            "|    value_loss         | 2.82     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 34.6     |\n",
            "|    ep_rew_mean        | 34.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.607   |\n",
            "|    explained_variance | 0.000247 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.572    |\n",
            "|    value_loss         | 2.51     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 38.1      |\n",
            "|    ep_rew_mean        | 38.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 408       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.425    |\n",
            "|    explained_variance | -0.000445 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.1       |\n",
            "|    value_loss         | 2.13      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 42.1      |\n",
            "|    ep_rew_mean        | 42.1      |\n",
            "| time/                 |           |\n",
            "|    fps                | 404       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.65     |\n",
            "|    explained_variance | -0.000617 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 0.649     |\n",
            "|    value_loss         | 1.77      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46       |\n",
            "|    ep_rew_mean        | 46       |\n",
            "| time/                 |          |\n",
            "|    fps                | 407      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.474   |\n",
            "|    explained_variance | -0.00595 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.85     |\n",
            "|    value_loss         | 1.42     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 48.9     |\n",
            "|    ep_rew_mean        | 48.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 409      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 20       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.404   |\n",
            "|    explained_variance | 0.000351 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.882    |\n",
            "|    value_loss         | 1.1      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 55        |\n",
            "|    ep_rew_mean        | 55        |\n",
            "| time/                 |           |\n",
            "|    fps                | 411       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.534    |\n",
            "|    explained_variance | -0.000594 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 0.495     |\n",
            "|    value_loss         | 0.823     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 58.8     |\n",
            "|    ep_rew_mean        | 58.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 413      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 22       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.505   |\n",
            "|    explained_variance | 0.000939 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | 0.295    |\n",
            "|    value_loss         | 0.584    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 62.8      |\n",
            "|    ep_rew_mean        | 62.8      |\n",
            "| time/                 |           |\n",
            "|    fps                | 414       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.547    |\n",
            "|    explained_variance | -0.000198 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 0.271     |\n",
            "|    value_loss         | 0.387     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 67.4      |\n",
            "|    ep_rew_mean        | 67.4      |\n",
            "| time/                 |           |\n",
            "|    fps                | 416       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.557    |\n",
            "|    explained_variance | -0.000216 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 0.22      |\n",
            "|    value_loss         | 0.225     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 72.6      |\n",
            "|    ep_rew_mean        | 72.6      |\n",
            "| time/                 |           |\n",
            "|    fps                | 417       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.585    |\n",
            "|    explained_variance | -5.96e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 0.104     |\n",
            "|    value_loss         | 0.109     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 77.2     |\n",
            "|    ep_rew_mean        | 77.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 418      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 27       |\n",
            "|    total_timesteps    | 11500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.416   |\n",
            "|    explained_variance | 0.000152 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | 0.162    |\n",
            "|    value_loss         | 0.0354   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 81.8     |\n",
            "|    ep_rew_mean        | 81.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 417      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.532   |\n",
            "|    explained_variance | 0.000918 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0178   |\n",
            "|    value_loss         | 0.00197  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 84.5     |\n",
            "|    ep_rew_mean        | 84.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 414      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 12500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.56    |\n",
            "|    explained_variance | -0.00501 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | 0.000929 |\n",
            "|    value_loss         | 9.32e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 91.1     |\n",
            "|    ep_rew_mean        | 91.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 415      |\n",
            "|    iterations         | 2600     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 13000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.51    |\n",
            "|    explained_variance | -0.0151  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2599     |\n",
            "|    policy_loss        | 0.00124  |\n",
            "|    value_loss         | 5.97e-06 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 94.6     |\n",
            "|    ep_rew_mean        | 94.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 416      |\n",
            "|    iterations         | 2700     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 13500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.368   |\n",
            "|    explained_variance | -0.0329  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2699     |\n",
            "|    policy_loss        | 0.00071  |\n",
            "|    value_loss         | 1.2e-06  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 98.8     |\n",
            "|    ep_rew_mean        | 98.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 417      |\n",
            "|    iterations         | 2800     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 14000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.544   |\n",
            "|    explained_variance | 0.3      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2799     |\n",
            "|    policy_loss        | 0.000179 |\n",
            "|    value_loss         | 1.54e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 104      |\n",
            "|    ep_rew_mean        | 104      |\n",
            "| time/                 |          |\n",
            "|    fps                | 418      |\n",
            "|    iterations         | 2900     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 14500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.469   |\n",
            "|    explained_variance | 0.122    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2899     |\n",
            "|    policy_loss        | 0.000126 |\n",
            "|    value_loss         | 2.27e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 107      |\n",
            "|    ep_rew_mean        | 107      |\n",
            "| time/                 |          |\n",
            "|    fps                | 419      |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.533   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | 5.19e-06 |\n",
            "|    value_loss         | 3.96e-10 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 111       |\n",
            "|    ep_rew_mean        | 111       |\n",
            "| time/                 |           |\n",
            "|    fps                | 420       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.423    |\n",
            "|    explained_variance | nan       |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | -2.08e-06 |\n",
            "|    value_loss         | 8.15e-11  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 114      |\n",
            "|    ep_rew_mean        | 114      |\n",
            "| time/                 |          |\n",
            "|    fps                | 421      |\n",
            "|    iterations         | 3200     |\n",
            "|    time_elapsed       | 37       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.435   |\n",
            "|    explained_variance | -5.87    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3199     |\n",
            "|    policy_loss        | 1.01e-05 |\n",
            "|    value_loss         | 2.22e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 119      |\n",
            "|    ep_rew_mean        | 119      |\n",
            "| time/                 |          |\n",
            "|    fps                | 422      |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.424   |\n",
            "|    explained_variance | -5.12    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 7.53e-06 |\n",
            "|    value_loss         | 1.98e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 124      |\n",
            "|    ep_rew_mean        | 124      |\n",
            "| time/                 |          |\n",
            "|    fps                | 422      |\n",
            "|    iterations         | 3400     |\n",
            "|    time_elapsed       | 40       |\n",
            "|    total_timesteps    | 17000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.415   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3399     |\n",
            "|    policy_loss        | 2.68e-06 |\n",
            "|    value_loss         | 5.01e-10 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 129      |\n",
            "|    ep_rew_mean        | 129      |\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.536   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | 8.75e-06 |\n",
            "|    value_loss         | 1.8e-09  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 134      |\n",
            "|    ep_rew_mean        | 134      |\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 3600     |\n",
            "|    time_elapsed       | 42       |\n",
            "|    total_timesteps    | 18000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.41    |\n",
            "|    explained_variance | -0.177   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3599     |\n",
            "|    policy_loss        | 0.000102 |\n",
            "|    value_loss         | 6.97e-08 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 138       |\n",
            "|    ep_rew_mean        | 138       |\n",
            "| time/                 |           |\n",
            "|    fps                | 420       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 43        |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.386    |\n",
            "|    explained_variance | -0.0601   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | -0.000465 |\n",
            "|    value_loss         | 8.96e-07  |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 143      |\n",
            "|    ep_rew_mean        | 143      |\n",
            "| time/                 |          |\n",
            "|    fps                | 420      |\n",
            "|    iterations         | 3800     |\n",
            "|    time_elapsed       | 45       |\n",
            "|    total_timesteps    | 19000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.497   |\n",
            "|    explained_variance | -0.265   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3799     |\n",
            "|    policy_loss        | -0.00011 |\n",
            "|    value_loss         | 1.26e-07 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 150      |\n",
            "|    ep_rew_mean        | 150      |\n",
            "| time/                 |          |\n",
            "|    fps                | 421      |\n",
            "|    iterations         | 3900     |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 19500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.464   |\n",
            "|    explained_variance | nan      |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3899     |\n",
            "|    policy_loss        | 1.25e-05 |\n",
            "|    value_loss         | 1.06e-09 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 156      |\n",
            "|    ep_rew_mean        | 156      |\n",
            "| time/                 |          |\n",
            "|    fps                | 421      |\n",
            "|    iterations         | 4000     |\n",
            "|    time_elapsed       | 47       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.269   |\n",
            "|    explained_variance | 0.0727   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3999     |\n",
            "|    policy_loss        | 0.00132  |\n",
            "|    value_loss         | 3.1e-06  |\n",
            "------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1).learn(budget)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3X0G0ng2OE",
        "outputId": "48a2df02-f361-48e8-bcf0-db11c83a45f0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:442.68 +/- 86.44\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-fi1-oKnUI2"
      },
      "source": [
        "**Your goal is to beat that baseline and get closer to the optimal score of 500**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvq8zizok1X_"
      },
      "source": [
        "Time to tune!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UaqCCH4gkRH_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uDUfeZcyjPKS",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "a59a9e37-98de-4bfc-c51e-592365e4e19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trial' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-cae63e11ba15>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m hyperparams = dict(\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"exponent_n_steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of steps to collect data before updating policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gamma\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# discount factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trial' is not defined"
          ]
        }
      ],
      "source": [
        "policy_kwargs = dict(\n",
        "    net_arch=[\n",
        "      dict(vf=[64, 64], pi=[64, 64]), # network architectures for actor/critic\n",
        "    ],\n",
        "    activation_fn=nn.Tanh,\n",
        ")\n",
        "\n",
        "hyperparams = dict(\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10), # number of steps to collect data before updating policy\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True),\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True), # discount factor\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True), # The maximum value for the gradient clipping\n",
        "    ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True), # Entropy coefficient for the loss calculation\n",
        ")\n",
        "\n",
        "model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)"
      ]
    },
    {
      "source": [
        "import optuna\n",
        "import torch.nn as nn\n",
        "\n",
        "def objective(trial):\n",
        "    policy_kwargs = dict(\n",
        "        net_arch=[\n",
        "            dict(vf=[64, 64], pi=[64, 64]),  # network architectures for actor/critic\n",
        "        ],\n",
        "        activation_fn=nn.Tanh,\n",
        "    )\n",
        "\n",
        "    hyperparams = dict(\n",
        "        n_steps=2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10),  # number of steps to collect data before updating policy\n",
        "        learning_rate=trial.suggest_float(\"lr\", 1e-5, 1, log=True),\n",
        "        gamma=trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True),  # discount factor\n",
        "        max_grad_norm=trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True),  # The maximum value for the gradient clipping\n",
        "        ent_coef=trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True),  # Entropy coefficient for the loss calculation\n",
        "    )\n",
        "\n",
        "    model = A2C(\"MlpPolicy\", \"CartPole-v1\", seed=8, verbose=1, **hyperparams).learn(budget)\n",
        "\n",
        "    # Evaluate the model and return the reward\n",
        "    mean_reward, _ = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "    return mean_reward\n",
        "\n",
        "# Create an Optuna study\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "# Optimize the objective function\n",
        "study.optimize(objective, n_trials=10) # You can adjust the number of trials\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters: \", study.best_params)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Yg7YgV1To4AG",
        "outputId": "85be44ab-13c7-47bc-df97-0ef0ef6ebea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:42:54,179] A new study created in memory with name: no-name-3f5c3e71-fc27-4715-a974-cedea071d940\n",
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.8     |\n",
            "|    ep_rew_mean        | 25.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 657      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 6400     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | 0.0158   |\n",
            "|    learning_rate      | 0.000106 |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 4.43     |\n",
            "|    value_loss         | 50.5     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 31.5     |\n",
            "|    ep_rew_mean        | 31.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 672      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 12800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.663   |\n",
            "|    explained_variance | 0.0218   |\n",
            "|    learning_rate      | 0.000106 |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 4.49     |\n",
            "|    value_loss         | 52.5     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 40.5     |\n",
            "|    ep_rew_mean        | 40.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 666      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 19200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.671   |\n",
            "|    explained_variance | 0.0388   |\n",
            "|    learning_rate      | 0.000106 |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 4.55     |\n",
            "|    value_loss         | 60.1     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:43:25,081] Trial 0 finished with value: 131.08 and parameters: {'exponent_n_steps': 6, 'lr': 0.00010596016190487673, 'gamma': 0.9117581376342152, 'max_grad_norm': 0.7400077121148131, 'ent_coef': 2.596119726967703e-08}. Best is trial 0 with value: 131.08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:43:54,746] Trial 1 finished with value: 9.28 and parameters: {'exponent_n_steps': 9, 'lr': 0.25180948810963255, 'gamma': 0.9002293901898478, 'max_grad_norm': 0.3236576014399565, 'ent_coef': 6.513814791862683e-06}. Best is trial 0 with value: 131.08.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 112      |\n",
            "|    ep_rew_mean        | 112      |\n",
            "| time/                 |          |\n",
            "|    fps                | 691      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 12800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.581   |\n",
            "|    explained_variance | 0.338    |\n",
            "|    learning_rate      | 0.000827 |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 0.263    |\n",
            "|    value_loss         | 2.76     |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:44:25,124] Trial 2 finished with value: 184.88 and parameters: {'exponent_n_steps': 7, 'lr': 0.0008271024458576228, 'gamma': 0.9068412878184587, 'max_grad_norm': 0.3601175262335027, 'ent_coef': 1.644480951640508e-05}. Best is trial 2 with value: 184.88.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 22.1     |\n",
            "|    ep_rew_mean        | 22.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 417      |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 1        |\n",
            "|    total_timesteps    | 800      |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.69    |\n",
            "|    explained_variance | 0.181    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 2.29     |\n",
            "|    value_loss         | 12.8     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 23.2     |\n",
            "|    ep_rew_mean        | 23.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 444      |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 1600     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.686   |\n",
            "|    explained_variance | 0.0919   |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 1.65     |\n",
            "|    value_loss         | 7.64     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 25.7     |\n",
            "|    ep_rew_mean        | 25.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 467      |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 2400     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.654   |\n",
            "|    explained_variance | 0.193    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -2.96    |\n",
            "|    value_loss         | 27.1     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 28.3     |\n",
            "|    ep_rew_mean        | 28.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 479      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 3200     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.588   |\n",
            "|    explained_variance | -0.104   |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -3.95    |\n",
            "|    value_loss         | 65.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 32.7     |\n",
            "|    ep_rew_mean        | 32.7     |\n",
            "| time/                 |          |\n",
            "|    fps                | 463      |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.6     |\n",
            "|    explained_variance | 0.449    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.29     |\n",
            "|    value_loss         | 0.161    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 37.9     |\n",
            "|    ep_rew_mean        | 37.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 465      |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 10       |\n",
            "|    total_timesteps    | 4800     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.647   |\n",
            "|    explained_variance | -0.0303  |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -6.03    |\n",
            "|    value_loss         | 155      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 41.3     |\n",
            "|    ep_rew_mean        | 41.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 472      |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 5600     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.631   |\n",
            "|    explained_variance | 0.169    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 0.0104   |\n",
            "|    value_loss         | 0.00814  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46.2     |\n",
            "|    ep_rew_mean        | 46.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 466      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 6400     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.618   |\n",
            "|    explained_variance | 0.481    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.0477   |\n",
            "|    value_loss         | 0.0122   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 47.2     |\n",
            "|    ep_rew_mean        | 47.2     |\n",
            "| time/                 |          |\n",
            "|    fps                | 467      |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 7200     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.651   |\n",
            "|    explained_variance | 0.405    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.0865   |\n",
            "|    value_loss         | 0.0331   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 50.3     |\n",
            "|    ep_rew_mean        | 50.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 472      |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.554   |\n",
            "|    explained_variance | -0.2     |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.0913   |\n",
            "|    value_loss         | 0.0218   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 55.1     |\n",
            "|    ep_rew_mean        | 55.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 477      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 8800     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.612   |\n",
            "|    explained_variance | -0.812   |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 0.0108   |\n",
            "|    value_loss         | 0.00171  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 57.1     |\n",
            "|    ep_rew_mean        | 57.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 480      |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 9600     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.632   |\n",
            "|    explained_variance | -0.63    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | 0.0224   |\n",
            "|    value_loss         | 0.00281  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 58       |\n",
            "|    ep_rew_mean        | 58       |\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 21       |\n",
            "|    total_timesteps    | 10400    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.456   |\n",
            "|    explained_variance | -1.57    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | 0.0698   |\n",
            "|    value_loss         | 0.0146   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 61.6     |\n",
            "|    ep_rew_mean        | 61.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 486      |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 23       |\n",
            "|    total_timesteps    | 11200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.288   |\n",
            "|    explained_variance | -23.9    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | 0.146    |\n",
            "|    value_loss         | 0.0344   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 66.8     |\n",
            "|    ep_rew_mean        | 66.8     |\n",
            "| time/                 |          |\n",
            "|    fps                | 486      |\n",
            "|    iterations         | 1500     |\n",
            "|    time_elapsed       | 24       |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.632   |\n",
            "|    explained_variance | -1.41    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1499     |\n",
            "|    policy_loss        | -0.0194  |\n",
            "|    value_loss         | 0.00202  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 71.5     |\n",
            "|    ep_rew_mean        | 71.5     |\n",
            "| time/                 |          |\n",
            "|    fps                | 481      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 12800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.52    |\n",
            "|    explained_variance | -1.91    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | 0.0301   |\n",
            "|    value_loss         | 0.00648  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 76.9     |\n",
            "|    ep_rew_mean        | 76.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 28       |\n",
            "|    total_timesteps    | 13600    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.542   |\n",
            "|    explained_variance | 0.815    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 0.0483   |\n",
            "|    value_loss         | 0.00869  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 83.3     |\n",
            "|    ep_rew_mean        | 83.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 477      |\n",
            "|    iterations         | 1800     |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 14400    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.576   |\n",
            "|    explained_variance | -0.667   |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1799     |\n",
            "|    policy_loss        | -0.0353  |\n",
            "|    value_loss         | 0.00312  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 88.3     |\n",
            "|    ep_rew_mean        | 88.3     |\n",
            "| time/                 |          |\n",
            "|    fps                | 479      |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 15200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.56    |\n",
            "|    explained_variance | -0.877   |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -0.0121  |\n",
            "|    value_loss         | 0.00125  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 94.6     |\n",
            "|    ep_rew_mean        | 94.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 480      |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 33       |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.614   |\n",
            "|    explained_variance | -6.18    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -0.00458 |\n",
            "|    value_loss         | 0.000176 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 100      |\n",
            "|    ep_rew_mean        | 100      |\n",
            "| time/                 |          |\n",
            "|    fps                | 482      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 16800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.615   |\n",
            "|    explained_variance | 0.647    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | 0.0142   |\n",
            "|    value_loss         | 0.00131  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 108      |\n",
            "|    ep_rew_mean        | 108      |\n",
            "| time/                 |          |\n",
            "|    fps                | 483      |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 17600    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.639   |\n",
            "|    explained_variance | 0.214    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -5.73    |\n",
            "|    value_loss         | 119      |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 114      |\n",
            "|    ep_rew_mean        | 114      |\n",
            "| time/                 |          |\n",
            "|    fps                | 479      |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 18400    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.58    |\n",
            "|    explained_variance | -11.4    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | -0.00322 |\n",
            "|    value_loss         | 0.000636 |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 119      |\n",
            "|    ep_rew_mean        | 119      |\n",
            "| time/                 |          |\n",
            "|    fps                | 481      |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 39       |\n",
            "|    total_timesteps    | 19200    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.569   |\n",
            "|    explained_variance | -12.3    |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | 0.0169   |\n",
            "|    value_loss         | 0.00215  |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 127      |\n",
            "|    ep_rew_mean        | 127      |\n",
            "| time/                 |          |\n",
            "|    fps                | 482      |\n",
            "|    iterations         | 2500     |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.616   |\n",
            "|    explained_variance | -0.386   |\n",
            "|    learning_rate      | 0.000369 |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -0.0118  |\n",
            "|    value_loss         | 0.000554 |\n",
            "------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:45:08,459] Trial 3 finished with value: 341.36 and parameters: {'exponent_n_steps': 3, 'lr': 0.0003693169167480457, 'gamma': 0.9416960948895655, 'max_grad_norm': 4.516897268568779, 'ent_coef': 0.016063975060344814}. Best is trial 3 with value: 341.36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:45:39,218] Trial 4 finished with value: 168.04 and parameters: {'exponent_n_steps': 9, 'lr': 0.0003903439609654816, 'gamma': 0.9714774641710404, 'max_grad_norm': 3.792271014877418, 'ent_coef': 0.0026854322572174134}. Best is trial 3 with value: 341.36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:46:08,447] Trial 5 finished with value: 12.06 and parameters: {'exponent_n_steps': 10, 'lr': 0.481179902494158, 'gamma': 0.9970254742403484, 'max_grad_norm': 0.5580247228374347, 'ent_coef': 0.0008686032676937287}. Best is trial 3 with value: 341.36.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:46:41,129] Trial 6 finished with value: 500.0 and parameters: {'exponent_n_steps': 9, 'lr': 0.004896463280331423, 'gamma': 0.9801432903737625, 'max_grad_norm': 2.269613395217342, 'ent_coef': 3.664709214881896e-06}. Best is trial 6 with value: 500.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:47:10,072] Trial 7 finished with value: 9.26 and parameters: {'exponent_n_steps': 10, 'lr': 0.018039883641268257, 'gamma': 0.9973722142515592, 'max_grad_norm': 0.5459186789285753, 'ent_coef': 0.00013216517240113385}. Best is trial 6 with value: 500.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 49.7      |\n",
            "|    ep_rew_mean        | 49.7      |\n",
            "| time/                 |           |\n",
            "|    fps                | 517       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 1         |\n",
            "|    total_timesteps    | 800       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.000797 |\n",
            "|    explained_variance | -0.786    |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 1.57e-05  |\n",
            "|    value_loss         | 0.0289    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 42        |\n",
            "|    ep_rew_mean        | 42        |\n",
            "| time/                 |           |\n",
            "|    fps                | 494       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 3         |\n",
            "|    total_timesteps    | 1600      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.46e-12 |\n",
            "|    explained_variance | 0.147     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 12.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 13.3      |\n",
            "|    ep_rew_mean        | 13.3      |\n",
            "| time/                 |           |\n",
            "|    fps                | 468       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 2400      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.03e-12 |\n",
            "|    explained_variance | 0.974     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 1.89      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.42      |\n",
            "|    ep_rew_mean        | 9.42      |\n",
            "| time/                 |           |\n",
            "|    fps                | 481       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 6         |\n",
            "|    total_timesteps    | 3200      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.04e-12 |\n",
            "|    explained_variance | 0.958     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.876     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.47      |\n",
            "|    ep_rew_mean        | 9.47      |\n",
            "| time/                 |           |\n",
            "|    fps                | 487       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 8         |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.01e-11 |\n",
            "|    explained_variance | 0.914     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 1.05      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.15      |\n",
            "|    ep_rew_mean        | 9.15      |\n",
            "| time/                 |           |\n",
            "|    fps                | 492       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 9         |\n",
            "|    total_timesteps    | 4800      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.33e-12 |\n",
            "|    explained_variance | 0.963     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.544     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.33      |\n",
            "|    ep_rew_mean        | 9.33      |\n",
            "| time/                 |           |\n",
            "|    fps                | 475       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 5600      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.15e-12 |\n",
            "|    explained_variance | 0.988     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.121     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.28     |\n",
            "|    ep_rew_mean        | 9.28     |\n",
            "| time/                 |          |\n",
            "|    fps                | 478      |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 6400     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -9.6e-12 |\n",
            "|    explained_variance | 0.968    |\n",
            "|    learning_rate      | 0.0229   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -0       |\n",
            "|    value_loss         | 0.083    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.45      |\n",
            "|    ep_rew_mean        | 9.45      |\n",
            "| time/                 |           |\n",
            "|    fps                | 479       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 7200      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.58e-12 |\n",
            "|    explained_variance | 0.991     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.0773    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.22      |\n",
            "|    ep_rew_mean        | 9.22      |\n",
            "| time/                 |           |\n",
            "|    fps                | 472       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.09e-11 |\n",
            "|    explained_variance | 0.966     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.821     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.23      |\n",
            "|    ep_rew_mean        | 9.23      |\n",
            "| time/                 |           |\n",
            "|    fps                | 477       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 8800      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.83e-12 |\n",
            "|    explained_variance | 0.978     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.192     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.38      |\n",
            "|    ep_rew_mean        | 9.38      |\n",
            "| time/                 |           |\n",
            "|    fps                | 480       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 9600      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.12e-12 |\n",
            "|    explained_variance | 0.946     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.285     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.39      |\n",
            "|    ep_rew_mean        | 9.39      |\n",
            "| time/                 |           |\n",
            "|    fps                | 484       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 10400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.63e-11 |\n",
            "|    explained_variance | 0.983     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.0977    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.29      |\n",
            "|    ep_rew_mean        | 9.29      |\n",
            "| time/                 |           |\n",
            "|    fps                | 486       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 11200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.88e-12 |\n",
            "|    explained_variance | 0.97      |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.257     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.32      |\n",
            "|    ep_rew_mean        | 9.32      |\n",
            "| time/                 |           |\n",
            "|    fps                | 488       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.47e-12 |\n",
            "|    explained_variance | 0.979     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.571     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.27     |\n",
            "|    ep_rew_mean        | 9.27     |\n",
            "| time/                 |          |\n",
            "|    fps                | 489      |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 12800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -7.2e-12 |\n",
            "|    explained_variance | 0.977    |\n",
            "|    learning_rate      | 0.0229   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -0       |\n",
            "|    value_loss         | 0.0823   |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.28      |\n",
            "|    ep_rew_mean        | 9.28      |\n",
            "| time/                 |           |\n",
            "|    fps                | 485       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 13600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -8.25e-12 |\n",
            "|    explained_variance | 0.991     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.133     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.38      |\n",
            "|    ep_rew_mean        | 9.38      |\n",
            "| time/                 |           |\n",
            "|    fps                | 484       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 14400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.83e-12 |\n",
            "|    explained_variance | 0.989     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.0977    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.32      |\n",
            "|    ep_rew_mean        | 9.32      |\n",
            "| time/                 |           |\n",
            "|    fps                | 486       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 15200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -6.78e-12 |\n",
            "|    explained_variance | 0.935     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.617     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.32      |\n",
            "|    ep_rew_mean        | 9.32      |\n",
            "| time/                 |           |\n",
            "|    fps                | 488       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.12e-11 |\n",
            "|    explained_variance | 0.96      |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.188     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 9.34     |\n",
            "|    ep_rew_mean        | 9.34     |\n",
            "| time/                 |          |\n",
            "|    fps                | 489      |\n",
            "|    iterations         | 2100     |\n",
            "|    time_elapsed       | 34       |\n",
            "|    total_timesteps    | 16800    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -8e-12   |\n",
            "|    explained_variance | 0.991    |\n",
            "|    learning_rate      | 0.0229   |\n",
            "|    n_updates          | 2099     |\n",
            "|    policy_loss        | -0       |\n",
            "|    value_loss         | 0.14     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.38      |\n",
            "|    ep_rew_mean        | 9.38      |\n",
            "| time/                 |           |\n",
            "|    fps                | 490       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 17600     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -9.64e-12 |\n",
            "|    explained_variance | 0.988     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.064     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.34      |\n",
            "|    ep_rew_mean        | 9.34      |\n",
            "| time/                 |           |\n",
            "|    fps                | 490       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 37        |\n",
            "|    total_timesteps    | 18400     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -5.43e-12 |\n",
            "|    explained_variance | 0.744     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 1.34      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.35      |\n",
            "|    ep_rew_mean        | 9.35      |\n",
            "| time/                 |           |\n",
            "|    fps                | 488       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 19200     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -1.08e-11 |\n",
            "|    explained_variance | 0.844     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.781     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 9.39      |\n",
            "|    ep_rew_mean        | 9.39      |\n",
            "| time/                 |           |\n",
            "|    fps                | 486       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -7.13e-12 |\n",
            "|    explained_variance | 0.987     |\n",
            "|    learning_rate      | 0.0229    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -0        |\n",
            "|    value_loss         | 0.0579    |\n",
            "-------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:47:51,276] Trial 8 finished with value: 9.46 and parameters: {'exponent_n_steps': 3, 'lr': 0.02289778684395328, 'gamma': 0.9337785774547616, 'max_grad_norm': 0.8362278357453944, 'ent_coef': 1.518591472778996e-05}. Best is trial 6 with value: 500.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Creating environment from the given name 'CartPole-v1'\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:48:20,473] Trial 9 finished with value: 9.34 and parameters: {'exponent_n_steps': 8, 'lr': 0.6326649862657749, 'gamma': 0.9850554360179489, 'max_grad_norm': 4.688944757772995, 'ent_coef': 5.863355519133899e-08}. Best is trial 6 with value: 500.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'exponent_n_steps': 9, 'lr': 0.004896463280331423, 'gamma': 0.9801432903737625, 'max_grad_norm': 2.269613395217342, 'ent_coef': 3.664709214881896e-06}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "id": "H9jXO1e9iTzi",
        "outputId": "05890bae-8808-4fff-b29b-f17b1025f861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward:417.38 +/- 99.50\n"
          ]
        }
      ],
      "source": [
        "mean_reward, std_reward = evaluate_policy(model, eval_envs_cartpole, n_eval_episodes=50, deterministic=True)\n",
        "\n",
        "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL_G9DurUV75"
      },
      "source": [
        "Hint - Recommended Hyperparameter Range\n",
        "\n",
        "```python\n",
        "gamma = trial.suggest_float(\"gamma\", 0.9, 0.99999, log=True)\n",
        "max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "# from 2**3 = 8 to 2**10 = 1024\n",
        "n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "learning_rate = trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "ent_coef = trial.suggest_float(\"ent_coef\", 0.00000001, 0.1, log=True)\n",
        "# net_arch tiny: {\"pi\": [64], \"vf\": [64]}\n",
        "# net_arch default: {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "# activation_fn = nn.Tanh / nn.ReLU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFOp0j-ga-_"
      },
      "source": [
        "# Part III: Automatic Hyperparameter Tuning\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88x7wMyyud5p"
      },
      "source": [
        "In this part we will create a script that allows to search for the best hyperparameters automatically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auwR-30IvHeY"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VM6tUr-yuekR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQVfmM1dzA1d"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yyBTVcAGzCRk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "N_TRIALS = 100  # Maximum number of trials\n",
        "N_JOBS = 1 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "N_TIMESTEPS = int(2e4)  # Training budget\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_ENVS = 5\n",
        "N_EVAL_EPISODES = 10\n",
        "TIMEOUT = int(60 * 15)  # 15 minutes\n",
        "\n",
        "ENV_ID = \"CartPole-v1\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25HgcDYzvJ0b"
      },
      "source": [
        "### Exercise (5 minutes): Define the search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KXo8AwGAvN8Q",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from typing import Any, Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparameters.\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: The sampled hyperparameters for the given trial.\n",
        "    \"\"\"\n",
        "    # Discount factor between 0.9 and 0.9999\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    # 8, 16, 32, ... 1024\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # - define the learning rate search space [1e-5, 1] (log) -> `suggest_float`\n",
        "    # - define the network architecture search space [\"tiny\", \"small\"] -> `suggest_categorical`\n",
        "    # - define the activation function search space [\"tanh\", \"relu\"]\n",
        "    learning_rate = ...\n",
        "    net_arch = ...\n",
        "    activation_fn = ...\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    # Display true values\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]}\n",
        "        if net_arch == \"tiny\"\n",
        "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "        },\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iybymNiJxNu7"
      },
      "source": [
        "### Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJY8Z8tuxai7"
      },
      "source": [
        "First we define a custom callback to report the results of periodic evaluations to Optuna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "U5ijWTPzxSmd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"\n",
        "    Callback used for evaluating and reporting a trial.\n",
        "\n",
        "    :param eval_env: Evaluation environement\n",
        "    :param trial: Optuna trial object\n",
        "    :param n_eval_episodes: Number of evaluation episodes\n",
        "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
        "    :param deterministic: Whether the evaluation should\n",
        "        use a stochastic or deterministic policy.\n",
        "    :param verbose:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Evaluate policy (done in the parent class)\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            # Send report to Optuna\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cHNM_cFO3vs"
      },
      "source": [
        "### Exercise (10 minutes): Define the objective function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76voi9AXxlCq"
      },
      "source": [
        "Then we define the objective function that is in charge of sampling hyperparameters, creating the model and then returning the result to Optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E0yEokTDxhrC",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    \"\"\"\n",
        "    Objective function using by Optuna to evaluate\n",
        "    one configuration (i.e., one set of hyperparameters).\n",
        "\n",
        "    Given a trial object, it will sample hyperparameters,\n",
        "    evaluate it and report the result (mean episodic reward after training)\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: Mean episodic reward after training\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # 1. Sample hyperparameters and update the default keyword arguments: `kwargs.update(other_params)`\n",
        "    # 2. Create the evaluation envs\n",
        "    # 3. Create the `TrialEvalCallback`\n",
        "\n",
        "    # 1. Sample hyperparameters and update the keyword arguments\n",
        "\n",
        "    # Create the RL model\n",
        "    model = A2C(**kwargs)\n",
        "\n",
        "    # 2. Create envs used for evaluation using `make_vec_env`, `ENV_ID` and `N_EVAL_ENVS`\n",
        "\n",
        "    # 3. Create the `TrialEvalCallback` callback defined above that will periodically evaluate\n",
        "    # and report the performance using `N_EVAL_EPISODES` every `EVAL_FREQ`\n",
        "    # TrialEvalCallback signature:\n",
        "    # TrialEvalCallback(eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose)\n",
        "    eval_callback = ...\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        # Sometimes, random hyperparams can generate NaN\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        # Free memory\n",
        "        model.env.close()\n",
        "        eval_envs.close()\n",
        "\n",
        "    # Tell the optimizer that the trial failed\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMFLu_M0ymzj"
      },
      "source": [
        "### The optimization loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4UU17YpjymPr",
        "vscode": {
          "languageId": "python"
        },
        "outputId": "7dc02229-faa5-4116-c4d0-e550579786a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-18 23:49:14,034] A new study created in memory with name: no-name-9a139bad-1a24-466a-b6e6-f1ec4c906404\n",
            "[W 2025-03-18 23:49:14,043] Trial 0 failed with parameters: {} because of the following error: TypeError(\"'ellipsis' object is not callable\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-31-a8c496f28b2a>\", line 38, in objective\n",
            "    model.learn(N_TIMESTEPS, callback=eval_callback)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/a2c/a2c.py\", line 201, in learn\n",
            "    return super().learn(\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 323, in learn\n",
            "    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\", line 224, in collect_rollouts\n",
            "    if not callback.on_step():\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\", line 114, in on_step\n",
            "    return self._on_step()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\", line 337, in _on_step\n",
            "    return self.callback(self.locals, self.globals)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: 'ellipsis' object is not callable\n",
            "[W 2025-03-18 23:49:14,045] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'ellipsis' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9f733bdb6878>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_TRIALS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_JOBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-a8c496f28b2a>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_TIMESTEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Sometimes, random hyperparams can generate NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     ) -> SelfA2C:\n\u001b[0;32m--> 201\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Give access to local variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_locals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_training_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not callable"
          ]
        }
      ],
      "source": [
        "import torch as th\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "th.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCbep6z1h3D1"
      },
      "source": [
        "Complete example: https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yUeYnfJVpB2"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "What we have seen in this notebook:\n",
        "- the importance of good hyperparameters\n",
        "- how to do automatic hyperparameter search with optuna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3-gqIPXqV7zZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "icra22_optuna_lab.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}